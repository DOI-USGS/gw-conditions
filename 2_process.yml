target_default: 2_process

packages:
  - dplyr
  - readr
  - tidyr
  - scico
  - sf

sources:
  - 2_process/src/compare_to_historic.R
  - 2_process/src/categorize_quantiles.R
  - 2_process/src/process_spatial.R
  - 2_process/src/prep_data_for_visualizing.R
  - 3_visualize/src/sf_utils_shift.R

targets:

  2_process:
    depends:
      - 2_process/out/gw_daily_quantiles.csv
      - 2_process/out/gw_data_anomalies.csv
      - gw_sites_sf
      - visualizations/data/gw-conditions-time-labels.csv.ind
  
  # Sites that use "depth below" as their gw level need to be inversed. In the 
  # current implementation, this means any site that used pcode == '72019'
  depth_below_sites: 
    command: c(gw_sites_dv, gw_sites_uv)
    
  # Calculate quantiles of each  daily value
  2_process/out/gw_daily_quantiles.csv:
    command: compare_to_historic(
      target_name,
      historic_quantile_fn = "1_fetch/out/historic_gw_quantiles.csv",
      current_data_fn = "1_fetch/out/gw_data.csv",
      inverse_sites = depth_below_sites)
  
  # Summarize GWL data quantiles as very high, high, normal, low, or very low
  2_process/out/gw_data_anomalies.csv:
    command: categorize_quantiles(
      target_name,
      quantile_data_fn = "2_process/out/gw_daily_quantiles.csv",
      anomaly_bins = anomaly_bins,
      anomaly_categories = anomaly_categories)

  # Create spatial objects to use in mapping
  gw_sites_sf:
    command: convert_to_spatial_obj(
      gw_quantile_site_info, 
      proj_str,
      gw_anomaly_data)
  # Apply shifting to the sites 
  gw_sites_sf_shifted:
    command: apply_shifts_to_sites(
      sites_sf = gw_sites_sf,
      sites_info = gw_quantile_site_info,
      proj_str = proj_str)

  # Prepare data for peaks SVG
  gw_anomaly_data:
    command: read_csv("2_process/out/gw_data_anomalies.csv", col_types = I('cDnnc'))
  gw_time:
    command: generate_time(gw_anomaly_data)
  2_process/out/gw-conditions-time-labels.csv:
    command: generate_months(target_name, gw_time)
  gw_anomaly_data_w_paths:
    command: add_paths_to_data(gw_anomaly_data)
  gw_anomaly_data_w_colors:
    command: add_colors_to_data(gw_anomaly_data_w_paths, scico_palette, gw_time)

  # Unzip and prepare higher resolution spatial data for territories outside of CONUS
  2_process/out/nws_states.shp:
    command: open_highres_spatial_zip(
      out_file = target_name,
      in_zip = '1_fetch/out/nws_states.zip',
      tmp_dir = I('2_process/tmp'))

  ##-- Now push the data needed by Vue to S3 --##

  visualizations/data/gw-conditions-time-labels.csv.ind:
    command: s3_put(target_name, '2_process/out/gw-conditions-time-labels.csv', config_file = I('lib/cfg/s3_config_viz.yml'))
